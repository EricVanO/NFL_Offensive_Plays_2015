{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook queries the MySQL database that includes the results from import_game_pbp_data.py. It then trains a neural network on the data using sklearn's MLPClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn as skl\n",
    "import MySQLdb as mdb\n",
    "import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the database root password: ········\n"
     ]
    }
   ],
   "source": [
    "rootpass = getpass.getpass('Enter the database root password: ')\n",
    "con = mdb.connect('localhost', 'root', rootpass, 'NFL_Offensive_Plays_2015')\n",
    "cur = con.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below cell is the bulk of the notebook: it queries the database, trains the neural network on the data, makes predictions, and calculates the fraction of correctly predicted plays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_frac_true_cv = []\n",
    "best_model = []\n",
    "best_frac_true_train = []\n",
    "frac_true_test = []\n",
    "\n",
    "# A list of the team names.\n",
    "teams = ['Baltimore Ravens', 'Cincinnati Bengals', 'Cleveland Browns', 'Pittsburgh Steelers', 'Houston Texans', 'Indianapolis Colts', 'Jacksonville Jaguars', 'Tennessee Titans', 'Buffalo Bills', 'Miami Dolphins', 'New England Patriots', 'New York Jets', 'Denver Broncos', 'Kansas City Chiefs', 'Oakland Raiders', 'San Diego Chargers', 'Chicago Bears', 'Detroit Lions', 'Green Bay Packers', 'Minnesota Vikings', 'Atlanta Falcons', 'Carolina Panthers', 'New Orleans Saints', 'Tampa Bay Buccaneers', 'Dallas Cowboys', 'New York Giants', 'Philadelphia Eagles', 'Washington Redskins', 'Arizona Cardinals', 'St. Louis Rams', 'San Francisco 49ers', 'Seattle Seahawks']\n",
    "\n",
    "for team in teams:\n",
    "    #Get the training data\n",
    "    cur.execute(\"SELECT `Time Remaining`, Down, `To Go`, `Field Position`, `Score Differential` FROM `\" + team + \"` WHERE Week <= 8\")\n",
    "    train_in_prelim = cur.fetchall()\n",
    "    cur.execute(\"SELECT IsPass FROM `\" + team + \"` WHERE Week <= 8\")\n",
    "    train_out_prelim = cur.fetchall()\n",
    "\n",
    "    #Get the cross-validation data\n",
    "    cur.execute(\"SELECT `Time Remaining`, Down, `To Go`, `Field Position`, `Score Differential` FROM `\" + team + \"` WHERE Week > 8 AND Week <= 12\")\n",
    "    cv_in_prelim = cur.fetchall()\n",
    "    cur.execute(\"SELECT IsPass FROM `\" + team + \"` WHERE Week > 8 AND Week <= 12\")\n",
    "    cv_out_prelim = cur.fetchall()\n",
    "\n",
    "    #Get the test data\n",
    "    cur.execute(\"SELECT `Time Remaining`, Down, `To Go`, `Field Position`, `Score Differential` FROM `\" + team + \"` WHERE Week > 12\")\n",
    "    test_in_prelim = cur.fetchall()\n",
    "    cur.execute(\"SELECT IsPass FROM `\" + team + \"` WHERE Week > 12\")\n",
    "    test_out_prelim = cur.fetchall()\n",
    "\n",
    "    \"\"\"The fetchall() command returns a triply-nested tuple, which the functions from \n",
    "    sklearn do not like. In the next set of lines I convert the outputs to lists of lists,\n",
    "    which work as inputs to sklearn.StandardScaler and sklearn.MLPClassifier.\"\"\"\n",
    "    train_in = []\n",
    "    train_out = []\n",
    "    i = 0\n",
    "    while i < len(train_out_prelim):\n",
    "        train_out.append(float(train_out_prelim[i][0]))\n",
    "        train_in.append([float(train_in_prelim[i][0]), float(train_in_prelim[i][1]), float(train_in_prelim[i][2]), float(train_in_prelim[i][3]), float(train_in_prelim[i][4])])\n",
    "        i+=1\n",
    "    \n",
    "    cv_in = []\n",
    "    cv_out = []\n",
    "    i = 0\n",
    "    while i < len(cv_out_prelim):\n",
    "        cv_out.append(float(cv_out_prelim[i][0]))\n",
    "        cv_in.append([float(cv_in_prelim[i][0]), float(cv_in_prelim[i][1]), float(cv_in_prelim[i][2]), float(cv_in_prelim[i][3]), float(cv_in_prelim[i][4])])\n",
    "        i+=1\n",
    "    \n",
    "    test_in = []\n",
    "    test_out = []\n",
    "    i = 0\n",
    "    while i < len(test_out_prelim):\n",
    "        test_out.append(float(test_out_prelim[i][0]))\n",
    "        test_in.append([float(test_in_prelim[i][0]), float(test_in_prelim[i][1]), float(test_in_prelim[i][2]), float(test_in_prelim[i][3]), float(test_in_prelim[i][4])])\n",
    "        i+=1\n",
    "    \n",
    "    # Normalize the features.\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(train_in)\n",
    "    train_in = scaler.transform(train_in)\n",
    "    cv_in = scaler.transform(cv_in)\n",
    "    test_in = scaler.transform(test_in)\n",
    "\n",
    "    \"\"\"Here, I define the classifier. I used GridSearchCV to help find the values for each hyperparameter.\n",
    "    If I add more neurons to the hidden layer, the optimal regularization parameter (alpha) becomes large\n",
    "    (>= 1), suggesting that I have a high variance problem if I use more neurons without a lot of \n",
    "    regularization. If I have only one neuron in the hidden layer, the optimal regularization parameter  \n",
    "    seems to be zero, suggesting that I have a high bias problem in that case. Thus, I chose 2 neurons in\n",
    "    the hidden layer. The optimal regularization parameter in this case is 0.1.\"\"\"\n",
    "    \n",
    "    from sklearn.neural_network import MLPClassifier as mlpc\n",
    "    classifier = mlpc(solver='lbfgs', hidden_layer_sizes=(2,), activation='logistic', alpha=0.1, max_iter=float(\"inf\"))\n",
    "\n",
    "    \"\"\"For each team, I will run the classifier 100 times, trying to ensure that I get the optimal result.\n",
    "    I define the 'optimal' model as the one that does best on the cross-validation set, and I will save\n",
    "    the best models and the fraction of true predictions on the cross-validation and training sets.\"\"\"\n",
    "    i = 0\n",
    "    best_frac_true_cv.append(0.0)\n",
    "    best_model.append(None)\n",
    "    best_frac_true_train.append(0.0)\n",
    "    while i < 100:\n",
    "        model = classifier.fit(train_in,train_out)\n",
    "        train_predictions = classifier.predict(train_in)\n",
    "        j = 0\n",
    "        count = 0\n",
    "        while j < len(train_out):\n",
    "            if train_predictions[j] == train_out[j]:\n",
    "                count += 1\n",
    "            j += 1\n",
    "        frac_true_train = float(count)/float(len(train_predictions))\n",
    "    \n",
    "        cv_predictions = classifier.predict(cv_in)\n",
    "        j = 0\n",
    "        count = 0\n",
    "        while j < len(cv_out):\n",
    "            if cv_predictions[j] == cv_out[j]:\n",
    "                count += 1\n",
    "            j += 1\n",
    "        frac_true_cv = float(count)/float(len(cv_predictions))\n",
    "    \n",
    "        if frac_true_cv > best_frac_true_cv[-1]:\n",
    "            best_model[-1] = model\n",
    "            best_frac_true_train[-1] = frac_true_train\n",
    "            best_frac_true_cv[-1] = frac_true_cv\n",
    "        i+=1\n",
    "    \n",
    "    # Here, I use the best model from above to predict the output of the test set.\n",
    "    test_predictions = best_model[-1].predict(test_in)\n",
    "    i = 0\n",
    "    count = 0\n",
    "    while i < len(test_predictions):\n",
    "        if test_predictions[i] == test_out[i]:\n",
    "            count += 1\n",
    "        i += 1\n",
    "    frac_true_test.append(float(count)/float(len(test_out)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below cell defines frac_true_logit, which is a list of fractions of correct predictions from the logistic regression model in NFL_Off_Plays_Logit. I put it here so that I can compare the results of the two models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frac_true_logit = [0.6789667896678967,0.68,0.655511811023622,0.5580952380952381,0.6311787072243346,0.6360078277886497,0.6703296703296703,0.6610486891385767,0.6648550724637681,0.6338797814207651,0.6303972366148531,0.6766256590509666,0.6454388984509466,0.5803571428571429,0.6289752650176679,0.6679389312977099,0.6696588868940754,0.6257309941520468,0.5921875,0.7102803738317757,0.6750972762645915,0.6473594548551959,0.6863117870722434,0.6433566433566433,0.6819047619047619,0.6383763837638377,0.5942028985507246,0.5959780621572212,0.6400778210116731,0.7038461538461539,0.658008658008658,0.6227897838899804]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below cell calculates the difference between the fraction of correctly predicted plays by the model in this notebook and that in NFL_Off_Plays_Logit. In fact, there is little difference for any team, and the mean difference is slightly negative, favoring the logistic regression model. Since the logistic regression model is less computationally expensive to train, this suggests that logistic regression is a more appropriate way to predict play calls with this data. The fact that such a highly-biased model does as well as a neural network indicates that there is not enough data here to make a neural network worth the trouble. In particular, I imagine that having the personnel and formation used on each play would make a positive difference. Information on what the defense is doing pre-snap (are they showing man-to-man or zone coverage, etc.) would also be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.01088828, -0.07864865, -0.03012481,  0.06259442, -0.03714886,\n",
       "        -0.00322094,  0.01738963, -0.02674448, -0.03344482, -0.02331873,\n",
       "        -0.01597717, -0.00271262,  0.03148418, -0.02564016, -0.00316881,\n",
       "        -0.00621786, -0.05452731,  0.01297868, -0.02446416, -0.0161223 ,\n",
       "        -0.00738568, -0.06115256, -0.02259497,  0.04335222, -0.01882232,\n",
       "         0.02126217,  0.0225118 ,  0.02940893,  0.02985682, -0.01749929,\n",
       "         0.018559  ,  0.01550809]), -0.006035696316248125)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frac_true_diff = np.array(frac_true_test) - np.array(frac_true_logit)\n",
    "frac_true_diff, np.mean(frac_true_diff)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
