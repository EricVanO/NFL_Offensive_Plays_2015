{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This notebook queries and analyzes the data in the MySQL database called NFL_Offensive_Plays_2015, which results from running import_game_pbp_data.py. In particular, for each team, data from plays during the first 8 weeks of the 2015 NFL season--down, distance to go, field position, time remaining, and score differential--are used to train a logistic regression model, which is then used to try to predict whether plays from the last 9 weeks of the season would be runs or passes. In the end, the model makes correct predictions ~2/3 of the time, although it varies from team to team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "import MySQLdb as mdb\n",
    "import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the database root password: ········\n"
     ]
    }
   ],
   "source": [
    "# Connect to the MySQL database containing the results of import_game_pbp_data.py\n",
    "rootpass = getpass.getpass('Enter the database root password: ')\n",
    "con = mdb.connect('localhost', 'root', rootpass, 'NFL_Offensive_Plays_2015')\n",
    "cur = con.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell queries the database and performs logistic regression on the offensive play data for each team. The regression model is trained on the first 8 weeks of data, and tries to predict runs or passes for the remaining 9 weeks of data. I will also note here that three teams changed offensive coordinators midway throught the season. This is significant because a change in offensive coordinator usually results in a change in play calling. I don't expect my model to work well for these teams. The three teams are: Detroit Lions (Oct. 26, after Week 7), Indianapolis Colts (Nov. 3, after Week 8), St. Louis Rams (Dec. 7, after Week 13)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.591050\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.654667\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.573735\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.611577\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.575147\n",
      "         Iterations 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.582194\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.606127\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.599642\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.601416\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.601603\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.556362\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.563216\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.570971\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.636627\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.620863\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.580733\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.575791\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.588648\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.640976\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.635179\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.579782\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.612232\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.574943\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.629588\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.608784\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.592237\n",
      "         Iterations 9\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.637833\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.628672\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.568783\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.567647\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.612073\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.660044\n",
      "         Iterations 7\n"
     ]
    }
   ],
   "source": [
    "# A list of the team names.\n",
    "teams = ['Baltimore Ravens', 'Cincinnati Bengals', 'Cleveland Browns', 'Pittsburgh Steelers', 'Houston Texans', 'Indianapolis Colts', 'Jacksonville Jaguars', 'Tennessee Titans', 'Buffalo Bills', 'Miami Dolphins', 'New England Patriots', 'New York Jets', 'Denver Broncos', 'Kansas City Chiefs', 'Oakland Raiders', 'San Diego Chargers', 'Chicago Bears', 'Detroit Lions', 'Green Bay Packers', 'Minnesota Vikings', 'Atlanta Falcons', 'Carolina Panthers', 'New Orleans Saints', 'Tampa Bay Buccaneers', 'Dallas Cowboys', 'New York Giants', 'Philadelphia Eagles', 'Washington Redskins', 'Arizona Cardinals', 'St. Louis Rams', 'San Francisco 49ers', 'Seattle Seahawks']\n",
    "# Below, I initialize the lists of parameters I'll use for later analysis.\n",
    "logitList = []\n",
    "fitResult = []\n",
    "predIsTrue = [[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]]\n",
    "fracCorrect = []\n",
    "numPass = []\n",
    "fracPass = []\n",
    "fracUncertain = []\n",
    "fracUncertainOrSureRun = []\n",
    "# A list of the total yards (and points) for each team, in the order corresponding to that of teams.\n",
    "totYds = [5749,5728,5311,6327,5564,5142,5581,4988,5775,5307,5991,5925,5688,5299,5336,5949,5514,5547,5353,5139,5990,5871,6461,6014,5361,5956,5830,5661,6533,4761,4860,6058]\n",
    "pts = [328,419,278,423,339,333,376,299,379,310,465,387,355,405,359,320,335,358,368,365,339,500,408,342,275,420,377,388,489,280,238,423]\n",
    "\n",
    "\"\"\"For each team, I will perform logistic regression on the \n",
    "offensive plays data from the first half of the season to try to \n",
    "predict whether plays from the second half of the season will be\n",
    "a run or a pass.\"\"\"\n",
    "j = 0\n",
    "while j < len(teams):\n",
    "    #The first step is to get the data from the first half of the season from the MySQL database.\n",
    "    cur.execute(\"SELECT `Time Remaining`, Down, `To Go`, `Field Position`, `Score Differential` FROM `\" + teams[j] + \"` WHERE Week < 9\")\n",
    "    firstHalfData = cur.fetchall()\n",
    "    cur.execute(\"SELECT IsPass FROM `\" + teams[j] + \"` WHERE Week < 9\")\n",
    "    firstHalfOut = cur.fetchall()\n",
    "    \n",
    "    \"\"\"I call the inputs from the training set  firstHalfIn. \n",
    "    Each row in firstHalfIn includes the bias term, the down, \n",
    "    the distance, the field position (a number between 0 and 50; \n",
    "    it doesn't differentiate between sides of the field), and \n",
    "    # (score differential) divided by (time remaining in seconds plus .01). \n",
    "    I expect the probability of a pass to change monotonically with each \n",
    "    input: The higher the down, the higher the distance, the farther from \n",
    "    either goalline, and the lower the ratio between score differential and \n",
    "    time remaining, the higher I expect the probability of a pass to be. The\n",
    "    .01 is in the denominator of the last input to avoid singularities on the\n",
    "    rare occasions that a defensive penalty allows for an offensive play with\n",
    "    no time remaining on the clock.\"\"\"\n",
    "    firstHalfIn = []\n",
    "    for play in firstHalfData:\n",
    "        firstHalfIn.append([1, int(play[1]), int(play[2]), int(min(play[3], 100-play[3])), float(play[4])/(float(play[0])+.01)])\n",
    "\n",
    "    # I save the results of the fit result in a list.\n",
    "    logitList.append(sm.Logit(firstHalfOut, firstHalfIn))\n",
    "    fitResult.append(logitList[j].fit())\n",
    "\n",
    "    #Now, I get the data from the second half of the season (weeks 9-17)\n",
    "    cur.execute(\"SELECT `Time Remaining`, Down, `To Go`, `Field Position`, `Score Differential` FROM `\" + teams[j] + \"` WHERE Week > 8\")\n",
    "    secondHalfData = cur.fetchall()\n",
    "    cur.execute(\"SELECT IsPass FROM `\" + teams[j] + \"` WHERE Week > 8\")\n",
    "    secondHalfOut = cur.fetchall()\n",
    "    secondHalfIn = []\n",
    "    for play in secondHalfData:\n",
    "        secondHalfIn.append([1, int(play[1]), int(play[2]), int(min(play[3], 100-play[3])), float(play[4])/(float(play[0])+.01)])\n",
    "\n",
    "    \"\"\"I now need to use the results of the logistic regression to\n",
    "    make predictions about the second half of the season. Dotting\n",
    "    the second half data into the fitting parameters gives a list\n",
    "    of sigmoid funtion arguments. Applying the sigmoid function \n",
    "    to them gives a list of pass probabilites. Rounding these \n",
    "    probabilities gives the prediction of a run or pass.\"\"\"\n",
    "    secondHalfPred = []\n",
    "    sigmoids = 1/(1+np.exp(-np.dot(secondHalfIn, fitResult[j].params)))\n",
    "    for sigmoid in sigmoids:\n",
    "        secondHalfPred.append(round(sigmoid))\n",
    "\n",
    "    \"\"\"The following while loop fills in the list predIsTrue[j], \n",
    "    with ones indicating correct predictions, and zeros indicating\n",
    "    incorrect predictions. It also counts the number of true pass, \n",
    "    true run, false pass, and false run predictions there are.\n",
    "    It also counts plays where the model is uncertain--defined as \n",
    "    plays where the probability of a pass is between 40% and \n",
    "    60%--and plays where the probability of a pass is less than 60%. \n",
    "    This allows for more analysis later on.\"\"\"\n",
    "    \n",
    "    i = 0\n",
    "    tempUncertain = 0\n",
    "    tempUncertainOrSureRun = 0\n",
    "    while i < len(secondHalfPred):\n",
    "        if sigmoids[i] < .6:\n",
    "            tempUncertainOrSureRun += 1\n",
    "            if sigmoids[i] > .4:\n",
    "                tempUncertain += 1\n",
    "        if secondHalfPred[i] == secondHalfOut[i][0]:\n",
    "            predIsTrue[j].append(1)\n",
    "        else:\n",
    "            predIsTrue[j].append(0)\n",
    "        i += 1\n",
    "    \n",
    "    \"\"\"We now calculate the fraction of second half plays that were \n",
    "    correct predictions, correct pass predictions, correct run \n",
    "    predictions, false pass predictions, false run predictions, \n",
    "    uncertain predictions, and predictions that are uncertain or \n",
    "    sure of a run.\"\"\"\n",
    "    fracCorrect.append(float(sum(predIsTrue[j]))/float(len(predIsTrue[j])))\n",
    "    fracUncertain.append(float(tempUncertain)/float(len(predIsTrue[j])))\n",
    "    fracUncertainOrSureRun.append(float(tempUncertainOrSureRun)/float(len(predIsTrue[j])))\n",
    "    \n",
    "    \"\"\"# The next few lines find the total number of passing plays, \n",
    "    as well as the fraction of pass plays in the second half of the\n",
    "    season.\"\"\"\n",
    "    tempNumPass = 0\n",
    "    for play in secondHalfOut:\n",
    "        tempNumPass += play[0]\n",
    "    numPass.append(tempNumPass)\n",
    "    fracPass.append(float(numPass[j])/float(len(secondHalfOut)))\n",
    "    \n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A list of the fraction of plays the model correctly predicted, for each team. This number varies between ~55% and 70%, but it is often around 2/3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6789667896678967,\n",
       " 0.68,\n",
       " 0.6535433070866141,\n",
       " 0.55893536121673,\n",
       " 0.6311787072243346,\n",
       " 0.6360078277886497,\n",
       " 0.6703296703296703,\n",
       " 0.6610486891385767,\n",
       " 0.6648550724637681,\n",
       " 0.6338797814207651,\n",
       " 0.6303972366148531,\n",
       " 0.6766256590509666,\n",
       " 0.6454388984509466,\n",
       " 0.5803571428571429,\n",
       " 0.6289752650176679,\n",
       " 0.6679389312977099,\n",
       " 0.6696588868940754,\n",
       " 0.6257309941520468,\n",
       " 0.5953125,\n",
       " 0.7102803738317757,\n",
       " 0.6750972762645915,\n",
       " 0.6473594548551959,\n",
       " 0.6844106463878327,\n",
       " 0.6433566433566433,\n",
       " 0.6819047619047619,\n",
       " 0.6383763837638377,\n",
       " 0.5958132045088567,\n",
       " 0.5959780621572212,\n",
       " 0.6400778210116731,\n",
       " 0.7038461538461539,\n",
       " 0.658008658008658,\n",
       " 0.6227897838899804]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fracCorrect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "Below is a list of the fraction of plays for which the model was uncertain for each team. There is a lot of variance here, but for most teams this number is greater than .4. This suggests why my model can't predict more than ~2/3 of plays: on many plays it is not confident that the play will be a run or a pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.48523985239852396,\n",
       " 0.649090909090909,\n",
       " 0.4015748031496063,\n",
       " 0.3669201520912547,\n",
       " 0.44106463878326996,\n",
       " 0.48140900195694714,\n",
       " 0.47802197802197804,\n",
       " 0.41198501872659177,\n",
       " 0.4963768115942029,\n",
       " 0.21311475409836064,\n",
       " 0.10535405872193437,\n",
       " 0.4182776801405975,\n",
       " 0.3270223752151463,\n",
       " 0.5513392857142857,\n",
       " 0.3568904593639576,\n",
       " 0.4312977099236641,\n",
       " 0.3087971274685817,\n",
       " 0.4502923976608187,\n",
       " 0.5078125,\n",
       " 0.5626168224299065,\n",
       " 0.3949416342412451,\n",
       " 0.3577512776831346,\n",
       " 0.4296577946768061,\n",
       " 0.27972027972027974,\n",
       " 0.3980952380952381,\n",
       " 0.3929889298892989,\n",
       " 0.5442834138486312,\n",
       " 0.4954296160877514,\n",
       " 0.37937743190661477,\n",
       " 0.24807692307692308,\n",
       " 0.4588744588744589,\n",
       " 0.5913555992141454]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fracUncertain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I construct a list called difference. Each element of difference is equal to the fraction of plays the model got correct and the fraction of passing plays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.022140221402214055,\n",
       " 0.150909090909091,\n",
       " 0.027559055118110187,\n",
       " -0.1026615969581749,\n",
       " 0.0874524714828897,\n",
       " 0.015655577299412915,\n",
       " 0.0,\n",
       " 0.0674157303370786,\n",
       " 0.17210144927536225,\n",
       " 0.005464480874316946,\n",
       " 0.025906735751295318,\n",
       " 0.07381370826010547,\n",
       " 0.04819277108433728,\n",
       " 0.060267857142857206,\n",
       " 0.010600706713780994,\n",
       " 0.03816793893129766,\n",
       " 0.14721723518850982,\n",
       " 0.015594541910331383,\n",
       " -0.018749999999999933,\n",
       " 0.19439252336448598,\n",
       " 0.05642023346303504,\n",
       " 0.14821124361158428,\n",
       " 0.08174904942965777,\n",
       " 0.06293706293706292,\n",
       " 0.09523809523809523,\n",
       " 0.04428044280442811,\n",
       " 0.02898550724637683,\n",
       " 0.010968921389396646,\n",
       " 0.04474708171206221,\n",
       " 0.15192307692307694,\n",
       " 0.019480519480519543,\n",
       " 0.12377210216110024]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference = []\n",
    "i = 0\n",
    "while i < len(fracCorrect):\n",
    "    difference.append(fracCorrect[i] - fracPass[i])\n",
    "    i += 1\n",
    "difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I find out for which teams fracCorrect - fracPass is nonpositive. These cases are significant, because for these teams it is at least as accurate to guess pass on every play than to use this model. There are three teams for which this is true: the Pittsburgh Steelers, the Jacksonville Jaguars, and the Green Bay Packers. Surprisingly, none of these teams switched offensive coordinators mid-season, which is what I would have expected. For the Steelers, it makes sense: due to a mixture of suspensions and injuries, at different points of the season they did not have access to their starting runningback, wide receiver, and quarterback. This means that playcalling varied from game to game much more than it did for most teams to compensate for the different personnel. The Jaguars also had injuries to several wide receivers and running backs, which perhaps affected their playcalling throughout the season as well. The same is not true for the Packers, although their best wide receiver was out the whole season due to an injury during the preseason. Their offense did struggle early in the season, but largely recovered by the end of the season. Perhaps their play calls early on were different from those later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pittsburgh Steelers\n",
      "Jacksonville Jaguars\n",
      "Green Bay Packers\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "while i < len(difference):\n",
    "    if difference[i] <= 0:\n",
    "        print teams[i]\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I find out for which teams our model does at least 10 percentage points better than guessing pass on every play. I expected the teams on this list to have poor offenses during 2015, since it indicates that they were predictable. Some of them were dismal; However, this list also includes the Carolina Panthers, who had arguably the best offense that season. Perhaps the Panthers were so good that they were leading near the end of almost every game, and almost always ran at the end of the game as a result. That would make them very predictable, even though they were very good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cincinnati Bengals\n",
      "Buffalo Bills\n",
      "Chicago Bears\n",
      "Minnesota Vikings\n",
      "Carolina Panthers\n",
      "St. Louis Rams\n",
      "Seattle Seahawks\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "while i < len(difference):\n",
    "    if difference[i] >= .1:\n",
    "        print teams[i]\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing I wanted to find out from this is if the predictability of a team's offense--defined by how well my model is able to predict it--correlates with the success of that offense. In the cells below, I try to find correlations between different measures of predictability (fracCorrect, difference, fracUncertain, fracUncertainOrSureRun) and offensive success (total yards or total points). They are often correlated in the way one would expect (predictabile offenses usually did worse), but none of the correlations were statistically significant with a 95% confidence interval. Perhaps, if I included data from multiple seasons, I could find statistically significant results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.039</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1.201</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 21 Feb 2017</td> <th>  Prob (F-statistic):</th>  <td> 0.282</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:23:06</td>     <th>  Log-Likelihood:    </th> <td> -238.60</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    32</td>      <th>  AIC:               </th> <td>   481.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    30</td>      <th>  BIC:               </th> <td>   484.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 7210.6636</td> <td> 1432.437</td> <td>    5.034</td> <td> 0.000</td> <td> 4285.237  1.01e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>-2425.3636</td> <td> 2212.684</td> <td>   -1.096</td> <td> 0.282</td> <td>-6944.267  2093.539</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.229</td> <th>  Durbin-Watson:     </th> <td>   2.035</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.892</td> <th>  Jarque-Bera (JB):  </th> <td>   0.423</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.115</td> <th>  Prob(JB):          </th> <td>   0.809</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.486</td> <th>  Cond. No.          </th> <td>    41.0</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.039\n",
       "Model:                            OLS   Adj. R-squared:                  0.006\n",
       "Method:                 Least Squares   F-statistic:                     1.201\n",
       "Date:                Tue, 21 Feb 2017   Prob (F-statistic):              0.282\n",
       "Time:                        21:23:06   Log-Likelihood:                -238.60\n",
       "No. Observations:                  32   AIC:                             481.2\n",
       "Df Residuals:                      30   BIC:                             484.1\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
       "------------------------------------------------------------------------------\n",
       "const       7210.6636   1432.437      5.034      0.000      4285.237  1.01e+04\n",
       "x1         -2425.3636   2212.684     -1.096      0.282     -6944.267  2093.539\n",
       "==============================================================================\n",
       "Omnibus:                        0.229   Durbin-Watson:                   2.035\n",
       "Prob(Omnibus):                  0.892   Jarque-Bera (JB):                0.423\n",
       "Skew:                           0.115   Prob(JB):                        0.809\n",
       "Kurtosis:                       2.486   Cond. No.                         41.0\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fracCorrectFit = sm.OLS(totYds, sm.add_constant(fracCorrect))\n",
    "fracCorrectFitResult = fracCorrectFit.fit()\n",
    "fracCorrectFitResult.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>  -0.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>  0.5740</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 21 Feb 2017</td> <th>  Prob (F-statistic):</th>  <td> 0.455</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:24:43</td>     <th>  Log-Likelihood:    </th> <td> -238.93</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    32</td>      <th>  AIC:               </th> <td>   481.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    30</td>      <th>  BIC:               </th> <td>   484.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 5698.6939</td> <td>  106.831</td> <td>   53.343</td> <td> 0.000</td> <td> 5480.515  5916.872</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td> -936.6812</td> <td> 1236.376</td> <td>   -0.758</td> <td> 0.455</td> <td>-3461.698  1588.335</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.176</td> <th>  Durbin-Watson:     </th> <td>   2.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.916</td> <th>  Jarque-Bera (JB):  </th> <td>   0.389</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.009</td> <th>  Prob(JB):          </th> <td>   0.823</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.461</td> <th>  Cond. No.          </th> <td>    16.1</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.019\n",
       "Model:                            OLS   Adj. R-squared:                 -0.014\n",
       "Method:                 Least Squares   F-statistic:                    0.5740\n",
       "Date:                Tue, 21 Feb 2017   Prob (F-statistic):              0.455\n",
       "Time:                        21:24:43   Log-Likelihood:                -238.93\n",
       "No. Observations:                  32   AIC:                             481.9\n",
       "Df Residuals:                      30   BIC:                             484.8\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
       "------------------------------------------------------------------------------\n",
       "const       5698.6939    106.831     53.343      0.000      5480.515  5916.872\n",
       "x1          -936.6812   1236.376     -0.758      0.455     -3461.698  1588.335\n",
       "==============================================================================\n",
       "Omnibus:                        0.176   Durbin-Watson:                   2.032\n",
       "Prob(Omnibus):                  0.916   Jarque-Bera (JB):                0.389\n",
       "Skew:                          -0.009   Prob(JB):                        0.823\n",
       "Kurtosis:                       2.461   Cond. No.                         16.1\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DiffFit = sm.OLS(totYds, sm.add_constant(difference))\n",
    "DiffFitResult = DiffFit.fit()\n",
    "DiffFitResult.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>  -0.030</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td> 0.09067</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 21 Feb 2017</td> <th>  Prob (F-statistic):</th>  <td> 0.765</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:25:36</td>     <th>  Log-Likelihood:    </th> <td> -176.35</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    32</td>      <th>  AIC:               </th> <td>   356.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    30</td>      <th>  BIC:               </th> <td>   359.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>  352.5868</td> <td>   42.647</td> <td>    8.267</td> <td> 0.000</td> <td>  265.489   439.685</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>   29.6101</td> <td>   98.334</td> <td>    0.301</td> <td> 0.765</td> <td> -171.215   230.435</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.879</td> <th>  Durbin-Watson:     </th> <td>   2.326</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.644</td> <th>  Jarque-Bera (JB):  </th> <td>   0.446</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.289</td> <th>  Prob(JB):          </th> <td>   0.800</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.028</td> <th>  Cond. No.          </th> <td>    10.6</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.003\n",
       "Model:                            OLS   Adj. R-squared:                 -0.030\n",
       "Method:                 Least Squares   F-statistic:                   0.09067\n",
       "Date:                Tue, 21 Feb 2017   Prob (F-statistic):              0.765\n",
       "Time:                        21:25:36   Log-Likelihood:                -176.35\n",
       "No. Observations:                  32   AIC:                             356.7\n",
       "Df Residuals:                      30   BIC:                             359.6\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
       "------------------------------------------------------------------------------\n",
       "const        352.5868     42.647      8.267      0.000       265.489   439.685\n",
       "x1            29.6101     98.334      0.301      0.765      -171.215   230.435\n",
       "==============================================================================\n",
       "Omnibus:                        0.879   Durbin-Watson:                   2.326\n",
       "Prob(Omnibus):                  0.644   Jarque-Bera (JB):                0.446\n",
       "Skew:                           0.289   Prob(JB):                        0.800\n",
       "Kurtosis:                       3.028   Cond. No.                         10.6\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UncertainFit = sm.OLS(pts, sm.add_constant(fracUncertain))\n",
    "UncertainFitResult = UncertainFit.fit()\n",
    "UncertainFitResult.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.030</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>  -0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>  0.9173</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 21 Feb 2017</td> <th>  Prob (F-statistic):</th>  <td> 0.346</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:32:03</td>     <th>  Log-Likelihood:    </th> <td> -175.91</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    32</td>      <th>  AIC:               </th> <td>   355.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    30</td>      <th>  BIC:               </th> <td>   358.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>  323.2772</td> <td>   44.878</td> <td>    7.203</td> <td> 0.000</td> <td>  231.623   414.931</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>   76.8888</td> <td>   80.282</td> <td>    0.958</td> <td> 0.346</td> <td>  -87.069   240.847</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.833</td> <th>  Durbin-Watson:     </th> <td>   2.198</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.659</td> <th>  Jarque-Bera (JB):  </th> <td>   0.376</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.264</td> <th>  Prob(JB):          </th> <td>   0.829</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.061</td> <th>  Cond. No.          </th> <td>    9.67</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.030\n",
       "Model:                            OLS   Adj. R-squared:                 -0.003\n",
       "Method:                 Least Squares   F-statistic:                    0.9173\n",
       "Date:                Tue, 21 Feb 2017   Prob (F-statistic):              0.346\n",
       "Time:                        21:32:03   Log-Likelihood:                -175.91\n",
       "No. Observations:                  32   AIC:                             355.8\n",
       "Df Residuals:                      30   BIC:                             358.8\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
       "------------------------------------------------------------------------------\n",
       "const        323.2772     44.878      7.203      0.000       231.623   414.931\n",
       "x1            76.8888     80.282      0.958      0.346       -87.069   240.847\n",
       "==============================================================================\n",
       "Omnibus:                        0.833   Durbin-Watson:                   2.198\n",
       "Prob(Omnibus):                  0.659   Jarque-Bera (JB):                0.376\n",
       "Skew:                           0.264   Prob(JB):                        0.829\n",
       "Kurtosis:                       3.061   Cond. No.                         9.67\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UncertainOrSureRunFit = sm.OLS(pts, sm.add_constant(fracUncertainOrSureRun))\n",
    "UncertainOrSureRunFitResult = UncertainOrSureRunFit.fit()\n",
    "UncertainOrSureRunFitResult.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
